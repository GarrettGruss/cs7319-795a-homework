{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Single-Program Architecture Sentiment Analyzer\n",
    "\n",
    "This notebook implements sentiment analysis using a **single-program architecture**.\n",
    "The program reads a dataset, processes each line sequentially, classifies sentiment, and aggregates results.\n",
    "\n",
    "**Architectural characteristics:**\n",
    "- Simple, monolithic design\n",
    "- Sequential processing\n",
    "- Direct data flow\n",
    "- Single pass through data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataset path\n",
    "DATA_PATH = 'data/sample_us_posts.txt'\n",
    "KEYWORDS_PATH = 'data/keywords.csv'\n",
    "\n",
    "print(f'Using dataset: {DATA_PATH}')\n",
    "print(f'Using keywords: {KEYWORDS_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load Keywords from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keywords(keywords_path):\n",
    "    \"\"\"Load positive and negative keywords from CSV file.\"\"\"\n",
    "    positive_keywords = set()\n",
    "    negative_keywords = set()\n",
    "    \n",
    "    with open(keywords_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            keyword = row['keyword'].lower()\n",
    "            sentiment = row['sentiment'].lower()\n",
    "            \n",
    "            if sentiment == 'positive':\n",
    "                positive_keywords.add(keyword)\n",
    "            elif sentiment == 'negative':\n",
    "                negative_keywords.add(keyword)\n",
    "    \n",
    "    return positive_keywords, negative_keywords\n",
    "\n",
    "# Load keywords\n",
    "POS_KEYWORDS, NEG_KEYWORDS = load_keywords(KEYWORDS_PATH)\n",
    "print(f'Positive keywords: {POS_KEYWORDS}')\n",
    "print(f'Negative keywords: {NEG_KEYWORDS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Single-Program Sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Simple tokenization: letters and apostrophes only, case-insensitive.\"\"\"\n",
    "    # Extract words containing letters and apostrophes\n",
    "    words = re.findall(r\"[a-zA-Z']+\", text.lower())\n",
    "    return words\n",
    "\n",
    "def classify_sentiment(text, pos_keywords, neg_keywords):\n",
    "    \"\"\"Classify sentiment of a text line based on keyword presence.\"\"\"\n",
    "    words = set(tokenize(text))\n",
    "    \n",
    "    has_positive = bool(words & pos_keywords)\n",
    "    has_negative = bool(words & neg_keywords)\n",
    "    \n",
    "    if has_positive and has_negative:\n",
    "        return 'Mixed'\n",
    "    elif has_positive:\n",
    "        return 'Positive'\n",
    "    elif has_negative:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Test the classifier\n",
    "test_cases = [\n",
    "    \"I am so happy today!\",\n",
    "    \"I feel sad and depressed.\",\n",
    "    \"I love this but I'm also upset.\",\n",
    "    \"The weather is nice.\"\n",
    "]\n",
    "\n",
    "print(\"Testing classifier:\")\n",
    "for test in test_cases:\n",
    "    result = classify_sentiment(test, POS_KEYWORDS, NEG_KEYWORDS)\n",
    "    print(f'  \"{test}\" -> {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_file(file_path, pos_keywords, neg_keywords):\n",
    "    \"\"\"Single-program architecture: read file, classify each line, aggregate results.\"\"\"\n",
    "    counts = defaultdict(int)\n",
    "    total_lines = 0\n",
    "    \n",
    "    print(f\"Processing {file_path}...\")\n",
    "    \n",
    "    # Single pass through the data\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            line = line.strip()\n",
    "            if line:  # Skip empty lines\n",
    "                sentiment = classify_sentiment(line, pos_keywords, neg_keywords)\n",
    "                counts[sentiment] += 1\n",
    "                total_lines += 1\n",
    "                \n",
    "                # Progress indicator for large files\n",
    "                if line_num % 1000 == 0:\n",
    "                    print(f\"  Processed {line_num} lines...\")\n",
    "    \n",
    "    print(f\"Completed processing {total_lines} posts.\")\n",
    "    return dict(counts)\n",
    "\n",
    "# Process the dataset\n",
    "results = analyze_sentiment_file(DATA_PATH, POS_KEYWORDS, NEG_KEYWORDS)\n",
    "print(f\"\\nResults: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Generate Output and Verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_verdict(counts):\n",
    "    \"\"\"Generate verdict based on positive vs negative counts.\"\"\"\n",
    "    positive = counts.get('Positive', 0)\n",
    "    negative = counts.get('Negative', 0)\n",
    "    \n",
    "    if positive > negative:\n",
    "        return 'Happier'\n",
    "    elif negative > positive:\n",
    "        return 'Sadder'\n",
    "    else:\n",
    "        return 'Tied'\n",
    "\n",
    "def print_results(counts):\n",
    "    \"\"\"Print results in the required format.\"\"\"\n",
    "    positive = counts.get('Positive', 0)\n",
    "    negative = counts.get('Negative', 0)\n",
    "    mixed = counts.get('Mixed', 0)\n",
    "    neutral = counts.get('Neutral', 0)\n",
    "    \n",
    "    verdict = generate_verdict(counts)\n",
    "    \n",
    "    # Required output format\n",
    "    print(f\"Positive={positive} Negative={negative} Mixed={mixed} Neutral={neutral}\")\n",
    "    print(f\"Verdict: {verdict}\")\n",
    "    \n",
    "    return verdict\n",
    "\n",
    "# Generate and print results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "verdict = print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Optional: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart(counts, title=\"Sentiment Analysis Results\"):\n",
    "    \"\"\"Create a bar chart of sentiment counts.\"\"\"\n",
    "    labels = ['Positive', 'Negative', 'Mixed', 'Neutral']\n",
    "    values = [counts.get(label, 0) for label in labels]\n",
    "    colors = ['green', 'red', 'orange', 'gray']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(labels, values, color=colors, alpha=0.7)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, values):\n",
    "        if value > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                    str(value), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Sentiment Category', fontweight='bold')\n",
    "    plt.ylabel('Number of Posts', fontweight='bold')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add total count\n",
    "    total = sum(values)\n",
    "    plt.text(0.02, 0.95, f'Total Posts: {total}', transform=plt.gca().transAxes,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create visualization\n",
    "create_bar_chart(results, f\"Sentiment Analysis - {DATA_PATH} (Single-Program Architecture)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Test with Different Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with mixed dataset if available\n",
    "MIXED_DATA_PATH = 'data/sample_us_posts_mixed.txt'\n",
    "\n",
    "try:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"TESTING WITH: {MIXED_DATA_PATH}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    mixed_results = analyze_sentiment_file(MIXED_DATA_PATH, POS_KEYWORDS, NEG_KEYWORDS)\n",
    "    mixed_verdict = print_results(mixed_results)\n",
    "    \n",
    "    # Create chart for mixed dataset\n",
    "    create_bar_chart(mixed_results, f\"Sentiment Analysis - {MIXED_DATA_PATH} (Single-Program Architecture)\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Mixed dataset {MIXED_DATA_PATH} not found. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Architecture Summary\n",
    "\n",
    "**Single-Program Architecture Characteristics:**\n",
    "\n",
    "### Structure & Responsibilities\n",
    "- **Monolithic design**: All functionality in one program\n",
    "- **Sequential processing**: One line at a time, in order\n",
    "- **Single responsibility**: Read → Classify → Aggregate → Output\n",
    "- **Direct data flow**: Input file → Processing → Results\n",
    "\n",
    "### Advantages\n",
    "- **Simplicity**: Easy to understand and debug\n",
    "- **Low overhead**: No coordination between components\n",
    "- **Immediate results**: No intermediate storage needed\n",
    "- **Memory efficient**: Processes one line at a time\n",
    "\n",
    "### Limitations\n",
    "- **No parallelism**: Cannot utilize multiple cores effectively\n",
    "- **Scalability constraints**: Limited by single machine resources\n",
    "- **Fault tolerance**: Single point of failure\n",
    "- **Flexibility**: Harder to modify individual processing steps\n",
    "\n",
    "### Use Cases\n",
    "- Small to medium datasets (< 1GB)\n",
    "- Development and prototyping\n",
    "- Simple processing requirements\n",
    "- Single-machine environments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
