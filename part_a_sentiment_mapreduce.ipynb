{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: MapReduce-Style Architecture Sentiment Analyzer\n",
    "\n",
    "This notebook implements sentiment analysis using a **MapReduce-style architecture**.\n",
    "The processing follows the Map → Shuffle/Group → Reduce pattern to simulate distributed data processing.\n",
    "\n",
    "**Architectural characteristics:**\n",
    "- Parallel processing model\n",
    "- Data partitioning and grouping\n",
    "- Separate Map, Shuffle, and Reduce phases\n",
    "- Scalable design pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Dataset Path (edit if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/sample_us_posts.txt'  # TODO: change path if needed\nprint('Using dataset:', DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Keywords - Load from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Load keywords from CSV file\n",
    "def load_keywords():\n",
    "    pos_keywords = set()\n",
    "    neg_keywords = set()\n",
    "    \n",
    "    with open('keywords.csv', 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            keyword = row['keyword'].lower()\n",
    "            sentiment = row['sentiment'].lower()\n",
    "            \n",
    "            if sentiment == 'positive':\n",
    "                pos_keywords.add(keyword)\n",
    "            elif sentiment == 'negative':\n",
    "                neg_keywords.add(keyword)\n",
    "    \n",
    "    return pos_keywords, neg_keywords\n",
    "\n",
    "POS, NEG = load_keywords()\n",
    "print('POS:', POS, '\\nNEG:', NEG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Map Phase - Implement map_post Function\n",
    "\n",
    "The **Map** phase processes each line independently and emits key-value pairs.\n",
    "Each mapper classifies one post and emits `(sentiment_label, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_post(line: str):\n",
    "    \"\"\"Map function: classify one line and emit (label, 1)\n",
    "    \n",
    "    This simulates a distributed mapper that processes one post\n",
    "    and emits a key-value pair for the shuffle phase.\n",
    "    \"\"\"\n",
    "    # 1) Tokenize: lowercase and split into words\n",
    "    words = set(line.lower().split())\n",
    "    \n",
    "    # 2) Check keyword presence\n",
    "    has_positive = bool(words & POS)\n",
    "    has_negative = bool(words & NEG)\n",
    "    \n",
    "    # 3) Classify based on rules and emit (label, count)\n",
    "    if has_positive and has_negative:\n",
    "        return [('Mixed', 1)]\n",
    "    elif has_positive:\n",
    "        return [('Positive', 1)]\n",
    "    elif has_negative:\n",
    "        return [('Negative', 1)]\n",
    "    else:\n",
    "        return [('Neutral', 1)]\n",
    "\n",
    "# Test the map function\n",
    "test_cases = [\n",
    "    \"I am so happy today!\",\n",
    "    \"I feel sad and depressed.\",\n",
    "    \"I love this but I'm also upset.\",\n",
    "    \"The weather is nice.\"\n",
    "]\n",
    "\n",
    "print(\"Testing map_post function:\")\n",
    "for test in test_cases:\n",
    "    result = map_post(test)\n",
    "    print(f'  \"{test}\" -> {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Driver: Map Over Lines\n",
    "\n",
    "This phase simulates multiple mappers processing the dataset in parallel.\n",
    "Each line is processed by the map function to generate key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map phase: process all lines and collect (label, 1) pairs\n",
    "mapped = []\n",
    "line_count = 0\n",
    "\n",
    "print(f\"Map phase: Processing {DATA_PATH}...\")\n",
    "\n",
    "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:  # Skip empty lines\n",
    "            pairs = map_post(line)\n",
    "            mapped.extend(pairs)\n",
    "            line_count += 1\n",
    "\n",
    "print(f\"Map phase completed: {line_count} lines processed\")\n",
    "print(f\"Total mapped pairs: {len(mapped)}\")\n",
    "print('First few mapped items:', mapped[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Shuffle/Group Phase\n",
    "\n",
    "The **Shuffle** phase groups all values by their keys (sentiment labels).\n",
    "This simulates the distributed grouping that happens between Map and Reduce phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle/Group: group values by label\n",
    "print(\"Shuffle phase: Grouping mapped pairs by sentiment label...\")\n",
    "\n",
    "groups = {}\n",
    "for (label, value) in mapped:\n",
    "    if label not in groups:\n",
    "        groups[label] = []\n",
    "    groups[label].append(value)\n",
    "\n",
    "print('Shuffle phase completed')\n",
    "print('Groups (label -> count of values):', {k: len(v) for k, v in groups.items()})\n",
    "print('Sample from groups:')\n",
    "for label, values in groups.items():\n",
    "    print(f'  {label}: {values[:5]}...' if len(values) > 5 else f'  {label}: {values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Reduce Phase\n",
    "\n",
    "The **Reduce** phase aggregates values for each key (sentiment label).\n",
    "Each reducer sums up all the counts for its assigned sentiment category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce: sum values for each label\n",
    "print(\"Reduce phase: Aggregating counts for each sentiment label...\")\n",
    "\n",
    "totals = {}\n",
    "for label, values in groups.items():\n",
    "    totals[label] = sum(values)\n",
    "    print(f\"  Reducer for '{label}': {len(values)} values -> total = {totals[label]}\")\n",
    "\n",
    "print('Reduce phase completed')\n",
    "print('Final totals:', totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Print Counts and Verdict\n",
    "\n",
    "Generate the final output in the required format and compute the overall verdict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print counts and compute verdict\n",
    "positive = totals.get('Positive', 0)\n",
    "negative = totals.get('Negative', 0)\n",
    "mixed = totals.get('Mixed', 0)\n",
    "neutral = totals.get('Neutral', 0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MAPREDUCE RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Required output format\n",
    "print(f\"Positive={positive} Negative={negative} Mixed={mixed} Neutral={neutral}\")\n",
    "\n",
    "# Compute verdict\n",
    "if positive > negative:\n",
    "    verdict = 'Happier'\n",
    "elif negative > positive:\n",
    "    verdict = 'Sadder'\n",
    "else:\n",
    "    verdict = 'Tied'\n",
    "\n",
    "print(f\"Verdict: {verdict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Optional: Visualization with Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Chart 1: Sentiment Counts\n",
    "    labels = ['Positive', 'Negative', 'Mixed', 'Neutral']\n",
    "    values = [totals.get(label, 0) for label in labels]\n",
    "    colors = ['green', 'red', 'orange', 'gray']\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Subplot 1: Bar chart of counts\n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = plt.bar(labels, values, color=colors, alpha=0.7)\n",
    "    plt.title('Sentiment Counts (MapReduce Architecture)', fontweight='bold')\n",
    "    plt.xlabel('Sentiment Category')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, values):\n",
    "        if value > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                    str(value), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Subplot 2: Positive vs Negative percentage\n",
    "    plt.subplot(1, 2, 2)\n",
    "    pos_neg_total = positive + negative\n",
    "    if pos_neg_total > 0:\n",
    "        pos_pct = (positive / pos_neg_total) * 100\n",
    "        neg_pct = (negative / pos_neg_total) * 100\n",
    "        \n",
    "        plt.pie([pos_pct, neg_pct], \n",
    "                labels=[f'Positive\\n{positive} ({pos_pct:.1f}%)', \n",
    "                       f'Negative\\n{negative} ({neg_pct:.1f}%)'],\n",
    "                colors=['green', 'red'], \n",
    "                autopct='', \n",
    "                startangle=90,\n",
    "                alpha=0.7)\n",
    "        plt.title('Positive vs Negative Distribution', fontweight='bold')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No Positive/Negative\\nsentiments found', \n",
    "                ha='center', va='center', transform=plt.gca().transAxes,\n",
    "                fontsize=14, bbox=dict(boxstyle='round', facecolor='lightgray'))\n",
    "        plt.title('Positive vs Negative Distribution', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print('Chart skipped:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Configuration Options (Advanced)\n",
    "\n",
    "MapReduce systems often include configuration knobs for optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration knobs for MapReduce optimization\n",
    "USE_COMBINER = True  # Enable local aggregation before shuffle\n",
    "NUM_REDUCERS = 4     # Simulate multiple reducers (for partitioning)\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  USE_COMBINER: {USE_COMBINER}\")\n",
    "print(f\"  NUM_REDUCERS: {NUM_REDUCERS}\")\n",
    "\n",
    "if USE_COMBINER:\n",
    "    print(\"\\n[Combiner Phase - Local Aggregation]\")\n",
    "    print(\"In a real MapReduce system, combiners would:\")\n",
    "    print(\"- Reduce network traffic by pre-aggregating locally\")\n",
    "    print(\"- Run the same logic as reducers but on each mapper node\")\n",
    "    print(\"- Example: (Positive,1),(Positive,1),(Positive,1) -> (Positive,3)\")\n",
    "\n",
    "if NUM_REDUCERS > 1:\n",
    "    print(f\"\\n[Partitioning - {NUM_REDUCERS} Reducers]\")\n",
    "    print(\"In a real MapReduce system with multiple reducers:\")\n",
    "    for i in range(NUM_REDUCERS):\n",
    "        labels_for_reducer = [label for j, label in enumerate(['Positive', 'Negative', 'Mixed', 'Neutral']) \n",
    "                             if hash(label) % NUM_REDUCERS == i]\n",
    "        if labels_for_reducer:\n",
    "            print(f\"  Reducer {i}: handles {labels_for_reducer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Test with Different Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with mixed dataset\n",
    "MIXED_DATA_PATH = 'data/sample_us_posts_mixed.txt'\n",
    "\n",
    "def run_mapreduce_pipeline(data_path):\n",
    "    \"\"\"Run the complete MapReduce pipeline on a dataset\"\"\"\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(f\"RUNNING MAPREDUCE ON: {data_path}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Map phase\n",
    "    mapped = []\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                pairs = map_post(line)\n",
    "                mapped.extend(pairs)\n",
    "    \n",
    "    # Shuffle phase\n",
    "    groups = {}\n",
    "    for (label, value) in mapped:\n",
    "        if label not in groups:\n",
    "            groups[label] = []\n",
    "        groups[label].append(value)\n",
    "    \n",
    "    # Reduce phase\n",
    "    totals = {}\n",
    "    for label, values in groups.items():\n",
    "        totals[label] = sum(values)\n",
    "    \n",
    "    # Output\n",
    "    positive = totals.get('Positive', 0)\n",
    "    negative = totals.get('Negative', 0)\n",
    "    mixed = totals.get('Mixed', 0)\n",
    "    neutral = totals.get('Neutral', 0)\n",
    "    \n",
    "    print(f\"Positive={positive} Negative={negative} Mixed={mixed} Neutral={neutral}\")\n",
    "    \n",
    "    if positive > negative:\n",
    "        verdict = 'Happier'\n",
    "    elif negative > positive:\n",
    "        verdict = 'Sadder'\n",
    "    else:\n",
    "        verdict = 'Tied'\n",
    "    \n",
    "    print(f\"Verdict: {verdict}\")\n",
    "    return totals\n",
    "\n",
    "# Run on mixed dataset if available\n",
    "try:\n",
    "    mixed_totals = run_mapreduce_pipeline(MIXED_DATA_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Mixed dataset {MIXED_DATA_PATH} not found. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) MapReduce Architecture Summary\n",
    "\n",
    "**MapReduce Architecture Characteristics:**\n",
    "\n",
    "### Structure & Responsibilities\n",
    "- **Distributed design**: Separate Map, Shuffle, and Reduce phases\n",
    "- **Parallel processing**: Multiple mappers and reducers can run concurrently\n",
    "- **Data partitioning**: Data is split and processed independently\n",
    "- **Fault tolerance**: Failed tasks can be restarted on other nodes\n",
    "\n",
    "### MapReduce Phases\n",
    "1. **Map**: Process input records independently, emit key-value pairs\n",
    "2. **Shuffle/Group**: Sort and group intermediate data by key\n",
    "3. **Reduce**: Aggregate values for each key to produce final results\n",
    "\n",
    "### Advantages\n",
    "- **Scalability**: Can handle massive datasets across many machines\n",
    "- **Parallelism**: Utilizes multiple cores/machines effectively\n",
    "- **Fault tolerance**: Automatic handling of node failures\n",
    "- **Flexibility**: Easy to add new processing logic in map/reduce functions\n",
    "\n",
    "### Limitations\n",
    "- **Complexity**: More complex to understand and debug\n",
    "- **Overhead**: Network communication and coordination costs\n",
    "- **Latency**: Multiple phases introduce processing delays\n",
    "- **Overkill**: Unnecessary for small datasets\n",
    "\n",
    "### Use Cases\n",
    "- Big data processing (> 1TB)\n",
    "- Distributed computing environments\n",
    "- Batch processing jobs\n",
    "- Analytics on large datasets\n",
    "\n",
    "### Checklist Completed ✓\n",
    "- [x] Filled POS/NEG keywords from CSV\n",
    "- [x] Implemented `map_post` function\n",
    "- [x] Grouped mapped output into `groups` (Shuffle phase)\n",
    "- [x] Reduced to `totals` (Reduce phase)\n",
    "- [x] Printed totals and verdict\n",
    "- [x] Added charts and visualizations\n",
    "- [x] Tested with multiple datasets\n",
    "- [x] Added configuration options (combiner, multiple reducers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}